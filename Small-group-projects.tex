\documentclass[10pt]{article}
\usepackage{itcep, stmaryrd, tikz, pgflibraryplotmarks, multicol}
\usepackage[margin=1in, nohead, pdftex, includefoot]{geometry}
\usepackage{MnSymbol,wasysym}
\usepackage{hyperref}


\topmargin -0.2in
\pagestyle{empty}
\singlespacing
\let\oldhat\hat
\renewcommand{\vec}[1]{\mathbf{#1}}
\renewcommand{\hat}[1]{\oldhat{\mathbf{#1}}}

\definecolor{light-gray}{gray}{0.95}
\newcommand{\code}[1]{\colorbox{light-gray}{\texttt{#1}}}

\newcommand{\headerclass}{\code{<run>:\textbackslash the\textbackslash world} Machine Learning Camp}
\newcommand{\headersection}{Day 4: Exploring Data of Your Choice}
\newcommand{\headertitle}{Small group projects}

\def\C{\mathbb{C}}
\def\R{\mathbb{R}}
\parindent 0ex

%\cfoot{Kaisa Taipale, 2018}

\begin{document}
%==================================================================================================================================================
\headerclass\xspace \hspace{\stretch{1}} \headersection\\
\begin{center}{ \large \textbf{\headertitle} }\end{center}
%==================================================================================================================================================

We've concentrated on \textit{classification} because among supervised learning problems, classification is most different from what you might learn in a statistics class (often \textit{regression}) and the foundation for many methods of \textit{recommendation} and \textit{prediction}.

	\begin{center}
\textit{Big idea: if you can classify, you can often predict or recommend.}
\end{center}

Now you can move to small-group projects and work intensively on one dataset with the help of our instructors, TAs, and industry consultants.

\bigskip

\textbf{Suggested datasets:} Here are some suggested datasets. I really think starting with one of these will allow you to get the furthest, because we've cleaned the data and thought through solution strategies already:
\begin{itemize}
\item The Titanic! Survival classification/prediction. I actually haven't cleaned this data, but it's so well-studied that it is not too hard. Data already provided.
\item The Wisconsin breast cancer data set (diagnostic). It has the information about biopsies and your challenge would be to find the best model. \url{https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Diagnostic)}
\item The City of Austin animal shelter outcomes. Can you classify dogs into quick-adoption versus slow-adoption versus transfer, for instance? I can provide the data -- main problem is lots of categorical variables, so it won't be totally easy.
\item Diabetes: I know of a dataset with de-identified information about real-world hospital admissions for diabetes. Can you predict who will be re-admitted soon? Dataset at \url{https://archive.ics.uci.edu/ml/datasets/diabetes+130-us+hospitals+for+years+1999-2008}. It'll be hard due to some categorical values\ldots
\item Economic data: can you accurately classify which states voted for Trump and which for Clinton in the last presidential election based on economic data? We can help you find data.
\item House voting records from 115th House of Representatives. Can you classify representatives as Republican or Democrat by a random sample of their votes?
\item You can work through a facial data recognition problem, too!
\end{itemize}

You can choose your own dataset, too, but what I ask is that you pick a dataset in which you have data observations (features) and some specific outcome (a label) for each observation. This is required for a supervised classification problem.

There are tons of datasets in the world, and you have decades of life in which to grapple with them, so you might not be able to do your ideal machine learning problem this week! That's ok -- start it next week and email me about it!

\bigskip

\textbf{Process:}
\begin{enumerate}
\item Pick a dataset and ask the classification question (usually, "What gives the most accurate classification on test data?"). 
\item Explore the data. 
\begin{itemize}
\item What are all the columns? What do they mean? Dig into this.
\item What are summary statistics on each variable? Find the average, variance, and standard deviation for each variable. Find the min and max of each variable. Find how many records/observations have \textit{nothing} for that variable (just failed to record an answer).
\item How do the variables co-vary? That is, what's the covariance of all the variables? Use techniques like the heat map and scatter matrix in Python to visualize this -- these are really powerful. See the Titanic data analysis Jupyter notebook.
\end{itemize}
\item Once you've explored the data, divide your data into training and testing sets, or if you want to be very sophisticated, training, validation, and testing sets.
\item Think about which models might be best for your data: decision tree? random forest? linear support vector machine? support vector machine using the kernel trick? k-nearest neighbors? neural network? You can try them all or dig into a few!
\item Start modeling and comparing models. This is a great place to split up the work and assign certain people to certain models. Try all the models listed. Which is most accurate? Can you play with parameters to make one more accurate than another?
\item How are you going to present this? We heard from many speakers that the storytelling and communication aspect of work in machine learning was crucial. Start working on telling people about your data and justifying your decision-making regarding models. 
\end{enumerate}




\end{document}
